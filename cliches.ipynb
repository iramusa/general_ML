{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Imports\n",
    "Useful libraries."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 General\n",
    "Utilities useful for handling data, displaying, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2. sklearn\n",
    "Machine Learning library with models, methods for partitioning and preprocessing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.neural_network import BernoulliRBM\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn import linear_model, datasets, metrics\n",
    "from sklearn.cross_validation import train_test_split, StratifiedKFold, KFold\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3. scipy\n",
    "Mathematical functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.ndimage import convolve"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4. seaborn\n",
    "Data visualisations, pretty graphs and statistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Data preprocessing\n",
    "Loading data, splitting into sets, normalisations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1. Load data\n",
    "Training and testing sets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "FILE_TRAIN = 'mnist_kaggle/train.csv'\n",
    "train = pd.read_csv(FILE_TRAIN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "FILE_TEST = 'mnist_kaggle/test.csv'\n",
    "test = pd.read_csv(FILE_TEST)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split features and target variable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def split_variables(df, target_label):\n",
    "    \"\"\"Splits a pandas dataframe into features and target variables.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    df : a dataframe containing target_label column\n",
    "    target_label : a string name of the column\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    X : a dataframe with features\n",
    "    Y : a series with target values\n",
    "    \"\"\"\n",
    "    \n",
    "    X = df.ix[:, df.columns!=target_label]\n",
    "    Y = df[target_label]\n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TARGET_LABEL = 'label'\n",
    "X, y = split_variables(train, TARGET_LABEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_test = test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2. Split into training and validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.1 Stratified K-Fold for classification problems\n",
    "Because all categories of *y* should be present in similar proportions in the data sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "EVAL_FRAC = 0.1\n",
    "kf = StratifiedKFold(y, round(1./EVAL_FRAC))\n",
    "train_idx, valid_idx = next(iter(kf))\n",
    "X_train = X.ix[train_idx, :]\n",
    "y_train = y.ix[train_idx]\n",
    "X_valid = X.ix[valid_idx, :]\n",
    "y_valid = y.ix[valid_idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.2 Usual K-Fold for regression problems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "EVAL_FRAC = 0.1\n",
    "kf = KFold(len(y), round(1./EVAL_FRAC))\n",
    "train_idx, valid_idx = next(iter(kf))\n",
    "X_train = X.ix[train_idx, :]\n",
    "y_train = y.ix[train_idx]\n",
    "X_valid = X.ix[valid_idx, :]\n",
    "y_valid = y.ix[valid_idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.3 Splitting function\n",
    "Do the above in one line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_next_split(X, y, eval_frac, kfold):\n",
    "    \"\"\"Splits data into training and validation sets\n",
    "        \n",
    "    Parameters\n",
    "    ----------\n",
    "    X : a dataframe containing features\n",
    "    y : a series with target variable\n",
    "    eval_frac : fraction of data used for validation\n",
    "    kfold : (Stratified)KFold object\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    X_train, y_train, X_valid, y_valid : data split into training\n",
    "    and validation \n",
    "    \"\"\"\n",
    "    train_idx, valid_idx = next(iter(kf))\n",
    "    X_train = X.ix[train_idx, :]\n",
    "    y_train = y.ix[train_idx]\n",
    "    X_valid = X.ix[valid_idx, :]\n",
    "    y_valid = y.ix[valid_idx]\n",
    "    return X_train, y_train, X_valid, y_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train, y_train, X_valid, y_valid = get_next_split(X, y,\n",
    "                                                    EVAL_FRAC, kf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3. Preprocess"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3.1 Deal with non-full columns\n",
    "Replace NaNs or missing data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3.2 Categorical variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load Titanic data to show some examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Sex' 'Embarked']\n"
     ]
    }
   ],
   "source": [
    "# dummy function so that other variables are not overshadowed\n",
    "def titanic_demo():\n",
    "    f = 'titanic_kaggle/train.csv'\n",
    "    train = pd.read_csv(f)\n",
    "    target = 'Survived'\n",
    "    X, y = split_variables(train, target)\n",
    "    \n",
    "    X_tmp = X.drop(['Name', 'Ticket', 'Cabin'], axis=1)\n",
    "    X_cat = X_tmp.select_dtypes(include=['object'])\n",
    "    cat_labels = X_cat.columns.values\n",
    "    #print(cat_labels)\n",
    "    \n",
    "    # pandas way\n",
    "    X_1h = pd.get_dummies(X,\n",
    "                          prefix=cat_labels,\n",
    "                          columns=cat_labels)\n",
    "    #print(X_1h.head())\n",
    "\n",
    "    \n",
    "    #print(X_cat[cat_labels])\n",
    "    \n",
    "    # LabelEncoder + OneHotEncoder way\n",
    "    #feature = 'Sex'\n",
    "    #lbl = LabelEncoder()\n",
    "    #lbl.fit(X[feature])\n",
    "    #X = lbl.transform(X[feature])\n",
    "    #\n",
    "    #print(X)\n",
    "    \n",
    "    #ohe = OneHotEncoder()\n",
    "    #ohe.fit(X_lbl)\n",
    "    #X_1h = ohe.transform(X_lbl)\n",
    "    #print(X_1h.toarray())\n",
    "    \n",
    "    \n",
    "    \n",
    "titanic_demo()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract features by looking at the types of the variables. This is not always sufficient -- variables represented by numbers can be categorical (e.g. *y* in MNIST) -- have a look at Titanic data above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "X_cat = X.select_dtypes(include=['object'])\n",
    "print(X_cat.columns.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One hot encoding\n",
    "For pandas use *get_dummies* (see Titanic example).\n",
    "\n",
    "Otherwise use *OneHotEncoder* -- not there now (see Titanic example).\n",
    "\n",
    "### Decoding\n",
    "No general way. Fiddle with *df.stack* or have a solution specific\n",
    "to data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3.2 Numerical variables\n",
    "Bear in mind that numerical variables can be used to represent categories, thus automatic extraction is not fool-proof."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_num = X.select_dtypes(include=['float', 'int8', 'int16', 'int32', 'int64'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalise data\n",
    "- $x = \\frac{x - min(x)}{max(x) - mix(x)}$ - linearly scale data into range $[0, 1]$\n",
    "- $x = x - min(x)$ - shift data to zero\n",
    "- $x = log(1+x)$ - for numerical stability and mathematical reasons  (easier to catch trends) - only positive values allowed!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_num' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-21035003227b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m0.001\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mX_scaled\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mscale_01\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_num\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'X_num' is not defined"
     ]
    }
   ],
   "source": [
    "def scale_01(X):\n",
    "    return (X - X.min())/(X.max() - X.min() + 0.001)\n",
    "\n",
    "X_scaled = scale_01(X_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_log1p = np.log1p(X_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_zeroed = X_num - X_num.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def normalise_labels(X, labels):\n",
    "    X_tmp = X.copy()\n",
    "    X_tmp[labels] = scale_01(X[labels])\n",
    "    X_tmp[labels] = np.log1p(X[labels]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Restricted Boltzman Machine\n",
    "Binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
