{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Imports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 General\n",
    "Utilities useful for handling data, displaying, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2. sklearn\n",
    "Machine Learning library with models, methods for partitioning and preprocessing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.neural_network import BernoulliRBM\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn import linear_model, datasets, metrics\n",
    "from sklearn.cross_validation import train_test_split, StratifiedKFold, KFold\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, MaxAbsScaler\n",
    "from sklearn.preprocessing import Binarizer\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3. scipy\n",
    "Mathematical functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.ndimage import convolve"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4. seaborn\n",
    "Data visualisations, pretty graphs and statistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Data preprocessing\n",
    "Loading data, splitting into sets, normalisations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1. Load data\n",
    "Training and testing sets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "FILE_TRAIN = 'mnist_kaggle/train.csv'\n",
    "train = pd.read_csv(FILE_TRAIN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "FILE_TEST = 'mnist_kaggle/test.csv'\n",
    "test = pd.read_csv(FILE_TEST)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split features and target variable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def split_variables(df, target_label):\n",
    "    \"\"\"Splits a pandas dataframe into features and target variables.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    df : a dataframe containing target_label column\n",
    "    target_label : a string name of the column\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    X : a dataframe with features\n",
    "    Y : a series with target values\n",
    "    \"\"\"\n",
    "    \n",
    "    X = df.ix[:, df.columns!=target_label]\n",
    "    Y = df[target_label]\n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TARGET_LABEL = 'label'\n",
    "X, y = split_variables(train, TARGET_LABEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_test = test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2. Split into training and validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.1 Stratified K-Fold for classification problems\n",
    "Because all categories of *y* should be present in similar proportions in the data sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "EVAL_FRAC = 0.1\n",
    "kf = StratifiedKFold(y, round(1./EVAL_FRAC))\n",
    "train_idx, valid_idx = next(iter(kf))\n",
    "X_train = X.ix[train_idx, :]\n",
    "y_train = y.ix[train_idx]\n",
    "X_valid = X.ix[valid_idx, :]\n",
    "y_valid = y.ix[valid_idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.2 Usual K-Fold for regression problems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "EVAL_FRAC = 0.1\n",
    "kf = KFold(len(y), round(1./EVAL_FRAC))\n",
    "train_idx, valid_idx = next(iter(kf))\n",
    "X_train = X.ix[train_idx, :]\n",
    "y_train = y.ix[train_idx]\n",
    "X_valid = X.ix[valid_idx, :]\n",
    "y_valid = y.ix[valid_idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.3 Splitting function\n",
    "Do the above in one line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_next_split(X, y, eval_frac, kfold):\n",
    "    \"\"\"Splits data into training and validation sets\n",
    "        \n",
    "    Parameters\n",
    "    ----------\n",
    "    X : a dataframe containing features\n",
    "    y : a series with target variable\n",
    "    eval_frac : fraction of data used for validation\n",
    "    kfold : (Stratified)KFold object\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    X_train, y_train, X_valid, y_valid : data split into training\n",
    "    and validation \n",
    "    \"\"\"\n",
    "    train_idx, valid_idx = next(iter(kf))\n",
    "    X_train = X.ix[train_idx, :]\n",
    "    y_train = y.ix[train_idx]\n",
    "    X_valid = X.ix[valid_idx, :]\n",
    "    y_valid = y.ix[valid_idx]\n",
    "    return X_train, y_train, X_valid, y_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train, y_train, X_valid, y_valid = get_next_split(X, y,\n",
    "                                                    EVAL_FRAC, kf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3. Preprocessing\n",
    "http://scikit-learn.org/stable/modules/preprocessing.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3.1 Deal with non-full columns\n",
    "Replace NaNs or missing data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-> 4.3.5. Imputation of missing valuesÂ¶ -- see link above\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3.2 Categorical variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load Titanic data to show some examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# dummy function so that other variables are not overshadowed\n",
    "def titanic_demo():\n",
    "    f = 'titanic_kaggle/train.csv'\n",
    "    train = pd.read_csv(f)\n",
    "    target = 'Survived'\n",
    "    X, y = split_variables(train, target)\n",
    "    \n",
    "    X_tmp = X.drop(['Name', 'Ticket', 'Cabin'], axis=1)\n",
    "    X_cat = X_tmp.select_dtypes(include=['object'])\n",
    "    cat_labels = X_cat.columns.values\n",
    "    #print(cat_labels)\n",
    "    \n",
    "    # pandas way\n",
    "    X_1h = pd.get_dummies(X,\n",
    "                          prefix=cat_labels,\n",
    "                          columns=cat_labels)\n",
    "    #print(X_1h.head())\n",
    "\n",
    "    \n",
    "    #print(X_cat[cat_labels])\n",
    "    \n",
    "    # LabelEncoder + OneHotEncoder way\n",
    "    #feature = 'Sex'\n",
    "    #lbl = LabelEncoder()\n",
    "    #lbl.fit(X[feature])\n",
    "    #X = lbl.transform(X[feature])\n",
    "    #\n",
    "    #print(X)\n",
    "    \n",
    "    #ohe = OneHotEncoder()\n",
    "    #ohe.fit(X_lbl)\n",
    "    #X_1h = ohe.transform(X_lbl)\n",
    "    #print(X_1h.toarray())\n",
    "    \n",
    "titanic_demo()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract features by looking at the types of the variables. This is not always sufficient -- variables represented by numbers can be categorical (e.g. *y* in MNIST) -- have a look at Titanic data above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_cat = X.select_dtypes(include=['object'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One hot encoding\n",
    "For pandas use *get_dummies* (see Titanic example).\n",
    "\n",
    "Otherwise use *OneHotEncoder* -- does not work currently (see Titanic example).\n",
    "\n",
    "### Decoding\n",
    "No general way. Fiddle with *df.stack* or have a solution specific\n",
    "to data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3.2 Numerical variables\n",
    "Bear in mind that numerical variables can be used to represent categories, thus automatic extraction is not fool-proof."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_num = X.select_dtypes(include=['float', 'int8', 'int16', 'int32', 'int64'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalise data\n",
    "- $x = \\frac{x - min(x)}{max(x) - mix(x)}$ - linearly scale data into range $[0, 1]$\n",
    "- $x = x - min(x)$ - shift data to zero\n",
    "- $x = log(1+x)$ - for numerical stability and mathematical reasons  (easier to catch trends) - only positive values allowed!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def scale_01(X):\n",
    "    return (X - X.min())/(X.max() - X.min() + 0.001)\n",
    "\n",
    "X_scaled = scale_01(X_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_log1p = np.log1p(X_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_zeroed = X_num - X_num.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def normalise_labels(X, labels):\n",
    "    X_tmp = X[labels]\n",
    "    X_tmp[labels] = scale_01(X[labels])\n",
    "    X_tmp[labels] = np.log1p(X[labels]) \n",
    "    return X_tmp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### sklearn solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mms = MinMaxScaler()\n",
    "mab = MaxAbsScaler()\n",
    "ss = StandardScaler()\n",
    "b = Binarizer()\n",
    "\n",
    "b.fit(X_num)  \n",
    "X_binarised = b.transform(X_num)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Polynomial trasformation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-> 4.3.6. Generating polynomial features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Visualise data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1. Restricted Boltzman Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[BernoulliRBM] Iteration 1, pseudo-likelihood = -131.27, time = 2.79s\n",
      "[BernoulliRBM] Iteration 2, pseudo-likelihood = -122.31, time = 3.23s\n",
      "[BernoulliRBM] Iteration 3, pseudo-likelihood = -121.98, time = 3.20s\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import BernoulliRBM\n",
    "rbm = BernoulliRBM(random_state=0, verbose=True)\n",
    "rbm.learning_rate = 0.06\n",
    "rbm.n_iter = 3\n",
    "# More components tend to give better prediction performance, but larger\n",
    "# fitting time\n",
    "rbm.n_components = 50\n",
    "sample = rbm.fit(X_binarised)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 4.2. Autoencoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3. PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.4. SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.5. Convolutional NN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.6. Graphical Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 4.7. Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 4.7. Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 4.8. Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Validation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#metrics.classification_report(\n",
    "#    y_valid,\n",
    "#    classifier.predict(X_valid))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
